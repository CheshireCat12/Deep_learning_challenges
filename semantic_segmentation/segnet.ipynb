{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "segnet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZJaluhuf9Xk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "from torch.optim.lr_scheduler import StepLR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoEqdjqhgEDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# General Settings\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "EPOCHS = 30\n",
        "lr_rate = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr3R-NkagMSw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b4d11d49-47ea-4419-c463-1df12e8e3f7d"
      },
      "source": [
        "# Dataset Settings\n",
        "\n",
        "image_transform = transforms.Compose([\n",
        "    #transforms.CenterCrop(256),\n",
        "    transforms.Resize((375, 500)),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize([.485, .456, .406], [.229, .224, .225]),\n",
        "])\n",
        "target_transform = transforms.Compose([\n",
        "    transforms.CenterCrop(256),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "TRAIN_SETTINGS = {\n",
        "    \"root\": \"./data\",\n",
        "    \"image_set\": \"train\",\n",
        "    \"transform\": image_transform,\n",
        "    \"target_transform\": target_transform,\n",
        "    # \"transforms\": transforms.ToTensor(),\n",
        "    \"download\": True\n",
        "}\n",
        "\n",
        "TEST_SETTINGS = TRAIN_SETTINGS.copy()\n",
        "TEST_SETTINGS[\"image_set\"] = \"val\"\n",
        "\n",
        "# Create Dataset\n",
        "\n",
        "train_dataset = datasets.VOCSegmentation(**TRAIN_SETTINGS)\n",
        "test_dataset = datasets.VOCSegmentation(**TEST_SETTINGS)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n",
            "Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynAqSIoGgtd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loader Settings\n",
        "\n",
        "LOADER_SETTINGS = {\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"shuffle\": True\n",
        "}\n",
        "\n",
        "# Create Loader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, **LOADER_SETTINGS)\n",
        "val_loader = DataLoader(test_dataset, **LOADER_SETTINGS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBRejSLViGTj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d2792bd-fd6f-4459-9254-0545972a2de9"
      },
      "source": [
        "\n",
        "for imgs, segs in train_loader:\n",
        "\n",
        "    print(imgs.data.size())\n",
        "\n",
        "    save_image(imgs, \"tmp.png\")\n",
        "    break\n",
        "    \n",
        "    # for ind, (img_out, img_in) in enumerate(zip(imgs, segs)):\n",
        "\n",
        "    #     plt.imshow(img_out.data.permute(1, 2, 0).numpy().reshape(375, 500, 3))\n",
        "    # #     if ind > 63:\n",
        "    # #         break\n",
        "    # #     plt.figure('out')\n",
        "    # #     fig_out.add_subplot(8, 8, ind + 1)\n",
        "    # #     plt.imshow(img_out.permute(1, 2, 0).data.numpy().reshape(256, 256, 3))\n",
        "    # #     plt.axis('off')\n",
        "\n",
        "    # #     # plt.figure('in')\n",
        "    # #     # fig_in.add_subplot(8, 8, ind + 1)\n",
        "    # #     # plt.imshow(img_in.data.numpy().reshape(28, 28))\n",
        "    # #     # plt.axis('off')\n",
        "    #     break\n",
        "    # plt.show()\n",
        "    # break\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 3, 375, 500])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV2hfIUxi7gN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}