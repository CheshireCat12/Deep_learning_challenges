{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "segnet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZJaluhuf9Xk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "from torch.optim.lr_scheduler import StepLR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoEqdjqhgEDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# General Settings\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "EPOCHS = 30\n",
        "lr_rate = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr3R-NkagMSw",
        "colab_type": "code",
        "outputId": "22b7b5da-dcb8-4bee-c7a2-fee42f4b00ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Dataset Settings\n",
        "\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.CenterCrop(256),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([.485, .456, .406], [.229, .224, .225]),\n",
        "])\n",
        "target_transform = transforms.Compose([\n",
        "    transforms.CenterCrop(256),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "TRAIN_SETTINGS = {\n",
        "    \"root\": \"./data\",\n",
        "    \"image_set\": \"train\",\n",
        "    \"transform\": image_transform,\n",
        "    \"target_transform\": target_transform,\n",
        "    \"download\": True\n",
        "}\n",
        "\n",
        "TEST_SETTINGS = TRAIN_SETTINGS.copy()\n",
        "TEST_SETTINGS[\"image_set\"] = \"val\"\n",
        "\n",
        "# Create Dataset\n",
        "\n",
        "train_dataset = datasets.VOCSegmentation(**TRAIN_SETTINGS)\n",
        "test_dataset = datasets.VOCSegmentation(**TEST_SETTINGS)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n",
            "Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynAqSIoGgtd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loader Settings\n",
        "\n",
        "LOADER_SETTINGS = {\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"shuffle\": True\n",
        "}\n",
        "\n",
        "# Create Loader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, **LOADER_SETTINGS)\n",
        "val_loader = DataLoader(test_dataset, **LOADER_SETTINGS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yujKiTw4q8Xt",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzJJZRtJq8iC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBRejSLViGTj",
        "colab_type": "code",
        "outputId": "81ef218f-1760-49ff-d777-b4a6e7b0fbf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "palette = [0, 0, 0, 128, 0, 0, 0, 128, 0, 128, 128, 0, 0, 0, 128, 128, 0, 128, 0, 128, 128,\n",
        "           128, 128, 128, 64, 0, 0, 192, 0, 0, 64, 128, 0, 192, 128, 0, 64, 0, 128, 192, 0, 128,\n",
        "           64, 128, 128, 192, 128, 128, 0, 64, 0, 128, 64, 0, 0, 192, 0, 128, 192, 0, 0, 64, 128]\n",
        "\n",
        "tmp = Image.open(\"./data/VOCdevkit/VOC2012/SegmentationClass/2007_000032.png\").convert('P')\n",
        "tmp.show()\n",
        "tmp.save(\"sdfasd.png\")\n",
        "tmp.putpalette(palette)\n",
        "tmp.save(\"ea.png\")\n",
        "\n",
        "tmp2 = transforms.ToTensor()(tmp)\n",
        "coucou = transforms.ToPILImage()(tmp2)\n",
        "\n",
        "coucou.putpalette(palette)\n",
        "coucou.save(\"final.png\")\n",
        "\n",
        "for imgs, segs in train_loader:\n",
        "\n",
        "    print(imgs.data.size())\n",
        "    print(segs.data.size())\n",
        "    save_image(imgs, \"tmp.png\")\n",
        "    save_image(segs, \"test.png\")\n",
        "    \n",
        "    transformed = transforms.ToPILImage()(segs[0])\n",
        "    transformed.putpalette(palette)\n",
        "    transformed.save(\"final_test.png\")\n",
        "    break\n",
        "    "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 3, 256, 256])\n",
            "torch.Size([8, 1, 256, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV2hfIUxi7gN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}