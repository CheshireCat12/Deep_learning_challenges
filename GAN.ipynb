{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "eM1_eNxr7fo3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qlwQdtdP8K5-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Image preprocessing\n",
        "transform = transforms.Compose([transforms.Resize(64),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=(0.5, 0.5, 0.5),\n",
        "                                                     std=(0.5, 0.5, 0.5))])\n",
        "\n",
        "# transform = transforms.Compose([transforms.ToTensor(),\n",
        "#                                 transforms.Normalize(mean=(0.5, 0.5, 0.5),\n",
        "#                                                      std=(0.5, 0.5, 0.5))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A5y_U0C18X0d",
        "colab_type": "code",
        "outputId": "f34f7d2a-d9da-4cb1-98f2-bc6560f8d503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "stl10 = dsets.STL10(root=\"./dataLsun\",\n",
        "                   download=True,\n",
        "                  transform=transform)\n",
        "\n",
        "# Load CIFAR 10 dataset\n",
        "cifar_trainset = dsets.CIFAR10(root=\"./data\",\n",
        "                               train=True,\n",
        "                               download=True,\n",
        "                               transform=transform)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JtMQqR6P85Y8",
        "colab_type": "code",
        "outputId": "a478625a-2f9a-4515-8735-821ef04ae31d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "# Parameters loader\n",
        "cifar_loader = DataLoader(cifar_trainset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True)\n",
        "\n",
        "stl10_loader = DataLoader(stl10,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True)\n",
        "\n",
        "cifar_loader.dataset\n",
        "stl10_loader.dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset STL10\n",
              "    Number of datapoints: 5000\n",
              "    Split: train\n",
              "    Root Location: ./dataLsun\n",
              "    Transforms (if any): Compose(\n",
              "                             Resize(size=64, interpolation=PIL.Image.BILINEAR)\n",
              "                             ToTensor()\n",
              "                             Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
              "                         )\n",
              "    Target Transforms (if any): None"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "y-pu4_6eLKoT",
        "colab_type": "code",
        "outputId": "011fd10c-22f5-4c9c-9ba2-1c39dafd06c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "for val, _ in stl10_loader:\n",
        "    print(val.shape)\n",
        "    vutils.save_image(val,\n",
        "                              './temp.png',\n",
        "                              normalize=True)\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 3, 64, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2oAPwlVT9s3e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generator model\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, Z_dim, ngf, ncc):\n",
        "        super(Generator, self).__init__()\n",
        "        \n",
        "        self.layers = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d(Z_dim, ngf*8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf*8),\n",
        "            nn.ReLU(),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*4),\n",
        "            nn.ReLU(),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*2),\n",
        "            nn.ReLU(),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(ngf, ncc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (ncc) x 64 x 64\n",
        "        )\n",
        "        \n",
        "    def forward(self, input_):\n",
        "        output = self.layers(input_)\n",
        "        print(output.shape)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_eEU58qYG1eH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Discriminator model\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ndf, ncc):\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(ncc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            \n",
        "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf*2),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            \n",
        "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf*4),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            \n",
        "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf*8),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            \n",
        "            nn.Conv2d(ndf*8, 1, 4, 1, 0, bias=False),\n",
        "            # nn.Sigmoid()\n",
        "            \n",
        "        )\n",
        "    \n",
        "    def forward(self, input_):\n",
        "        # print(\"before\")\n",
        "        output = self.layers(input_)\n",
        "        print(output.shape)\n",
        "        # print(\"after\")\n",
        "        return output.view(-1, 1).squeeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T0jeX_vUF6RR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0crKBjSbBoS2",
        "colab_type": "code",
        "outputId": "857bf726-d621-4e39-ed03-abf7ac58f5fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Dimension of the latent space\n",
        "Z_dim = 128\n",
        "\n",
        "# Number of color channel in the final image\n",
        "ncc = 3\n",
        "\n",
        "# Number of ?\n",
        "ngf, ndf = 64, 64\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6Yo0ScXOGEf1",
        "colab_type": "code",
        "outputId": "30ef99a1-3eb8-4721-ccde-3f4a66edf468",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "cell_type": "code",
      "source": [
        "netG = Generator(Z_dim, ngf, ncc).to(device)\n",
        "netG.apply(weights_init)\n",
        "print(netG)\n",
        "\n",
        "netD = Discriminator(ndf, ncc).to(device)\n",
        "netD.apply(weights_init)\n",
        "print(netD)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (layers): Sequential(\n",
            "    (0): ConvTranspose2d(128, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU()\n",
            "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU()\n",
            "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): Tanh()\n",
            "  )\n",
            ")\n",
            "Discriminator(\n",
            "  (layers): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2)\n",
            "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RvVggvZgGsgT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Setup loss function\n",
        "criterion = nn.BCELoss()\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "fixed_noise = torch.randn(batch_size, Z_dim, 1, 1, device=device)\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "learning_rate = 0.0002\n",
        "nb_epochs = 30\n",
        "\n",
        "# Setup optimizer\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=learning_rate, betas=(0.5, 0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "liV637DQKQ3P",
        "colab_type": "code",
        "outputId": "b3781a19-99e6-4664-8c51-54ae2e55d489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2841
        }
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(nb_epochs):\n",
        "    for i, data in enumerate(cifar_loader, 0):\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        # train with real\n",
        "        netD.zero_grad()\n",
        "        \n",
        "        real_cpu = data[0].to(device)\n",
        "        batch_size = real_cpu.size(0)\n",
        "        label = torch.full((batch_size,), real_label, device=device)\n",
        "\n",
        "        output = netD(real_cpu)\n",
        "        # print(output)\n",
        "        # print(label)\n",
        "        errD_real = criterion(output, label) # 0.5 * torch.mean((output-label)**2) # criterion(output, label)\n",
        "        errD_real.backward()\n",
        "        \n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        # train with fake\n",
        "        noise = torch.randn(batch_size, Z_dim, 1, 1, device=device)\n",
        "        \n",
        "        fake = netG(noise)\n",
        "        label.fill_(fake_label)\n",
        "        output = netD(fake.detach())\n",
        "        \n",
        "        errD_fake = criterion(output, label) # 0.5 * torch.mean((output-label)**2) # criterion(output, label)\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        \n",
        "        errD = errD_real + errD_fake\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)  # fake labels are real for generator cost\n",
        "        output = netD(fake)\n",
        "        errG = criterion(output, label) # 0.5 * torch.mean((output-label)**2) # criterion(output, label)\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        optimizerG.step()\n",
        "\n",
        "        print(f'[{epoch}/{nb_epochs}][{i}/{len(cifar_loader)}]\\\n",
        "              Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f}\\\n",
        "              D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}')\n",
        "        if i % 100 == 0:\n",
        "            vutils.save_image(real_cpu,\n",
        "                              './real_samples.png',\n",
        "                              normalize=True)\n",
        "            fake = netG(fixed_noise)\n",
        "            vutils.save_image(fake.detach(),\n",
        "                              f'./fake_samples_epoch_{epoch}.png',\n",
        "                              normalize=True)\n",
        "\n",
        "    # do checkpointing\n",
        "    torch.save(netG.state_dict(), f'./netG_epoch_{epoch}.pth')\n",
        "    torch.save(netD.state_dict(), f'./netD_epoch_{epoch}.pth')\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][0/391]              Loss_D: 2.4020 Loss_G: 12.4874              D(x): 0.4877 D(G(z)): 0.3675 / -2.5063\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][1/391]              Loss_D: 10.5672 Loss_G: 33.4812              D(x): 2.4051 D(G(z)): 2.0548 / -4.7148\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][2/391]              Loss_D: 7.6727 Loss_G: 3.7971              D(x): -1.1091 D(G(z)): -0.4139 / -0.8127\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][3/391]              Loss_D: 8.9395 Loss_G: 21.2113              D(x): 0.3443 D(G(z)): 2.4656 / -3.5107\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][4/391]              Loss_D: 3.7131 Loss_G: 18.2287              D(x): 0.4620 D(G(z)): 0.4101 / -3.1992\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][5/391]              Loss_D: 3.4947 Loss_G: 20.0577              D(x): 0.6767 D(G(z)): 0.8423 / -3.4053\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][6/391]              Loss_D: 4.3182 Loss_G: 33.7502              D(x): 0.3699 D(G(z)): 1.3054 / -4.7571\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][7/391]              Loss_D: 3.9123 Loss_G: 24.0219              D(x): -0.0313 D(G(z)): 0.6846 / -3.8458\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][8/391]              Loss_D: 5.5367 Loss_G: 54.7922              D(x): 0.1352 D(G(z)): 1.6332 / -6.3450\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][9/391]              Loss_D: 2.6711 Loss_G: 16.3131              D(x): 0.2607 D(G(z)): 0.0733 / -2.9722\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][10/391]              Loss_D: 8.5268 Loss_G: 90.7204              D(x): 0.9810 D(G(z)): 2.5712 / -8.4688\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][11/391]              Loss_D: 6.5847 Loss_G: 0.7960              D(x): -0.7389 D(G(z)): -1.1503 / 0.4972\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][12/391]              Loss_D: 18.4589 Loss_G: 73.1173              D(x): 1.4012 D(G(z)): 4.0039 / -7.4969\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][13/391]              Loss_D: 4.6505 Loss_G: 8.1195              D(x): -0.2356 D(G(z)): -1.1057 / -1.7483\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][14/391]              Loss_D: 10.5833 Loss_G: 55.9456              D(x): 0.9062 D(G(z)): 2.8916 / -6.4232\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][15/391]              Loss_D: 4.2277 Loss_G: 7.4560              D(x): -0.2208 D(G(z)): -0.7381 / -1.6323\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][16/391]              Loss_D: 9.2151 Loss_G: 65.3427              D(x): 0.6620 D(G(z)): 2.7454 / -7.0407\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][17/391]              Loss_D: 5.3813 Loss_G: 0.9203              D(x): -0.0952 D(G(z)): -1.5124 / 0.4059\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][18/391]              Loss_D: 12.2391 Loss_G: 60.4143              D(x): 1.2345 D(G(z)): 3.2130 / -6.7257\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][19/391]              Loss_D: 4.4288 Loss_G: 2.5362              D(x): 0.3079 D(G(z)): -1.4912 / -0.4008\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][20/391]              Loss_D: 10.1308 Loss_G: 50.8812              D(x): 0.7642 D(G(z)): 2.9043 / -6.0810\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][21/391]              Loss_D: 4.0022 Loss_G: 3.9304              D(x): -0.0512 D(G(z)): -1.0414 / -0.8398\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][22/391]              Loss_D: 9.8526 Loss_G: 70.1808              D(x): 1.1969 D(G(z)): 2.9037 / -7.3380\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][23/391]              Loss_D: 4.5818 Loss_G: 1.0355              D(x): 0.0191 D(G(z)): -1.5324 / 0.1803\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][24/391]              Loss_D: 13.3889 Loss_G: 70.0042              D(x): 0.6750 D(G(z)): 3.3952 / -7.3245\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][25/391]              Loss_D: 6.7311 Loss_G: 0.6610              D(x): -0.3081 D(G(z)): -1.8971 / 0.6222\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][26/391]              Loss_D: 11.4980 Loss_G: 48.6418              D(x): 0.8777 D(G(z)): 3.1263 / -5.9233\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][27/391]              Loss_D: 4.0317 Loss_G: 1.9621              D(x): 0.3068 D(G(z)): -1.4679 / -0.2446\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "[0/30][28/391]              Loss_D: 7.4755 Loss_G: 41.7515              D(x): 1.0919 D(G(z)): 2.4822 / -5.4145\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 3, 64, 64])\n",
            "torch.Size([128, 1, 1, 1])\n",
            "torch.Size([128, 1, 1, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-e1413d78b390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0merrG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 0.5 * torch.mean((output-label)**2) # criterion(output, label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0merrG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mD_G_z2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0moptimizerG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "HrFqlgK7NHfi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}