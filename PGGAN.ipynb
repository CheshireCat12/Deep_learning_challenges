{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PGGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CheshireCat12/Deep_learning_challenges/blob/master/PGGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "x0nrCQ8ds-GN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3ixALv_ZtEM9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Image preprocessing\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=(0.5, ),\n",
        "                                                     std=(0.5, ))])\n",
        "\n",
        "\n",
        "fasion_mnist = datasets.FashionMNIST(root=\"./data\",\n",
        "                                     train=True,\n",
        "                                     transform=transform,\n",
        "                                     download=True)\n",
        "\n",
        "# Parameters\n",
        "params_loader = {'batch_size': 32,\n",
        "                 'shuffle': False}\n",
        "\n",
        "train_loader = DataLoader(fasion_mnist, **params_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eCRnCyVUtN6r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generator model\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, Z_dim, ngf, ncc):\n",
        "        super(Generator, self).__init__()\n",
        "        \n",
        "        self.layers = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            # in_channels, out_channels, kernel_size, stride=1, padding=0\n",
        "            # formula: (in-1)* stride - 2*padding + kernel_size\n",
        "            # 128 -> \n",
        "            \n",
        "            # 1 -> (1-1)*1 - 2*0 + 4 = 4\n",
        "            # in: (100 x 4 x 4)\n",
        "            nn.ConvTranspose2d(Z_dim, ngf*8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf*8),\n",
        "            nn.ReLU(),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*4),\n",
        "            nn.ReLU(),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*2),\n",
        "            nn.ReLU(),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(ngf, ngf, 4, 2, 1, bias=False),\n",
        "            nn.Tanh(),\n",
        "            # state size. (ncc) x 64 x 64\n",
        "            nn.ConvTranspose2d(ngf, ncc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (ncc) x 128 x 128\n",
        "        )\n",
        "        \n",
        "    def forward(self, input_):\n",
        "        output = self.layers(input_)\n",
        "        # print(output.shape)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uS7f5ktxvgsH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "fe703a29-3342-432b-b6b7-9801bc6379d5"
      },
      "cell_type": "code",
      "source": [
        "# Discriminator model\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_size, ncc=3, init_depth=64, max_depth=1024):\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        self.img_size = img_size\n",
        "        self.ncc = ncc\n",
        "        self.init_depth = init_depth\n",
        "        self.max_depth = max_depth\n",
        "        \n",
        "        self._create_layers()\n",
        "        \n",
        "    def _create_layers(self):\n",
        "        internal_layers = []\n",
        "        depth_in = self.ncc\n",
        "        depth_out = self.init_depth\n",
        "        \n",
        "        # Assume img size power of 2!\n",
        "        for _ in range(1, int(np.log2(self.img_size))-1):\n",
        "            # Reduce the img size by 2 each iteration\n",
        "            internal_layers += self._init_block(depth_in, depth_out)\n",
        "            depth_in = depth_out\n",
        "            if not depth_out == self.max_depth:\n",
        "                depth_out *= 2\n",
        "        \n",
        "        # Last layer different from the others : depth x 4 x 4 -> 1 x 1 x 1\n",
        "        internal_layers.append(nn.Conv2d(depth_in, 1, 4, 1, 0, bias=False))\n",
        "        \n",
        "        self.depth_in = depth_in\n",
        "        self.depth_out = depth_out\n",
        "        self.layers = nn.Sequential(*internal_layers)\n",
        "        \n",
        "    def _init_block(self, depth_in, depth_out):\n",
        "        block = [nn.Conv2d(depth_in, depth_out, 4, 2, 1, bias=False),\n",
        "                 nn.BatchNorm2d(depth_out),\n",
        "                 nn.LeakyReLU(0.2)]\n",
        "        \n",
        "        return block\n",
        "    \n",
        "    def from_rgb(self, dim):\n",
        "        layer = nn.Conv2d()\n",
        "    \n",
        "    def grow_network(self):\n",
        "        pass\n",
        "        \n",
        "        \n",
        "    \n",
        "    def forward(self, input_):\n",
        "        output = self.layers(input_)\n",
        "\n",
        "        return output.view(-1, 1).squeeze(1)\n",
        "    \n",
        "discriminator = Discriminator(4)\n",
        "print(discriminator)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discriminator(\n",
            "  (layers): Sequential(\n",
            "    (0): Conv2d(3, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mgKL4IGavjGO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iXDjs1IGvk37",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dimension of the latent space\n",
        "Z_dim = 100\n",
        "\n",
        "# Number of color channel in the final image\n",
        "ncc = 3\n",
        "\n",
        "# Number of internal node\n",
        "ngf, ndf = 64, 64\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KvAC2McyvtZy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}