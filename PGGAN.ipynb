{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PGGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CheshireCat12/Deep_learning_challenges/blob/master/PGGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "x0nrCQ8ds-GN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3ixALv_ZtEM9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Image preprocessing\n",
        "transform = transforms.Compose([transforms.Resize(32),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=(0.5, ),\n",
        "                                                     std=(0.5, ))])\n",
        "\n",
        "\n",
        "fasion_mnist = datasets.FashionMNIST(root=\"./data\",\n",
        "                                     train=True,\n",
        "                                     transform=transform,\n",
        "                                     download=True)\n",
        "\n",
        "# Parameters\n",
        "params_loader = {'batch_size': 64,\n",
        "                 'shuffle': False}\n",
        "\n",
        "train_loader = DataLoader(fasion_mnist, **params_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eCRnCyVUtN6r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generator model\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, Z_dim, ngf, ncc):\n",
        "        super(Generator, self).__init__()\n",
        "        \n",
        "        self.layers = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            # in_channels, out_channels, kernel_size, stride=1, padding=0\n",
        "            # formula: (in-1)* stride - 2*padding + kernel_size\n",
        "            # 128 -> \n",
        "            \n",
        "            # 1 -> (1-1)*1 - 2*0 + 4 = 4\n",
        "            # in: (100 x 4 x 4)\n",
        "            nn.ConvTranspose2d(Z_dim, ngf*8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf*8),\n",
        "            nn.ReLU(),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*4),\n",
        "            nn.ReLU(),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*2),\n",
        "            nn.ReLU(),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(ngf, ngf, 4, 2, 1, bias=False),\n",
        "            nn.Tanh(),\n",
        "            # state size. (ncc) x 64 x 64\n",
        "            nn.ConvTranspose2d(ngf, ncc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (ncc) x 128 x 128\n",
        "        )\n",
        "        \n",
        "    def forward(self, input_):\n",
        "        output = self.layers(input_)\n",
        "        # print(output.shape)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uS7f5ktxvgsH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2396
        },
        "outputId": "8674b438-6977-4f6a-e82f-ff327d1a0e23"
      },
      "cell_type": "code",
      "source": [
        "# Discriminator model\n",
        "\n",
        "# ref: https://github.com/nashory/pggan-pytorch/blob/master/network.py\n",
        "def get_named_module(model, module_name):\n",
        "    \"\"\"Return the module of the model given in parameters.\"\"\"\n",
        "    new_model = nn.Sequential()\n",
        "    \n",
        "    for name, m in model.named_children():\n",
        "        if name == module_name:\n",
        "            new_model.add_module(name, m)\n",
        "            new_model[-1].load_state_dict(m.state_dict())\n",
        "                \n",
        "    return new_model\n",
        "\n",
        "class ConcatenateLayers(nn.Module):\n",
        "    def __init__(self, trans_layer, new_layer):\n",
        "        super(ConcatenateLayers, self).__init__()\n",
        "        \n",
        "        self.trans_layer = trans_layer\n",
        "        self.new_layer = new_layer\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return (self.trans_layer(x), self.new_layer(x))\n",
        "    \n",
        "class FadeIn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FadeIn, self).__init__()\n",
        "        \n",
        "        self.alpha = 0.\n",
        "        \n",
        "    def update_alpha(self, delta):\n",
        "        self.alpha += delta\n",
        "        self.alpha = max(0., min(self.alpha, 1.))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x (tuple):\n",
        "                val_from_trans (torch.Tensor): Tensor from the transition layer\n",
        "                val_from_new (torch.Tensor): Tensor from the last added layer\n",
        "        \n",
        "        Return:\n",
        "            Fade in the tensor comming from the last added layer.\n",
        "            Formula: (1-alpha)*trans + alpha* new\n",
        "        \"\"\"\n",
        "        val_from_trans, val_from_new = x\n",
        "        out = torch.add((1.-self.alpha) * val_from_trans,\n",
        "                        self.alpha * val_from_new)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_size, ncc=3, init_depth=64, max_depth=1024):\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        self.img_size = img_size\n",
        "        self.ncc = ncc\n",
        "        self.init_depth = init_depth\n",
        "        self.max_depth = max_depth\n",
        "        self.resl = 8\n",
        "        \n",
        "        self.model = self._create_model()\n",
        "        self.dim = self.max_depth // 2\n",
        "        \n",
        "    def _create_model(self):\n",
        "        model = nn.Sequential()\n",
        "        \n",
        "        rgb_layer = self._from_rgb(self.max_depth)\n",
        "        init_layers = self._init_layers()\n",
        "        \n",
        "        model.add_module(\"rgb_layer\", rgb_layer)\n",
        "        model.add_module(\"init_layers\", init_layers)\n",
        "        \n",
        "        return model\n",
        "        \n",
        "    def _block(self, depth_in, depth_out, last=False, stride=2, padding=1):\n",
        "        block = [nn.Conv2d(in_channels=depth_in,\n",
        "                           out_channels=depth_out,\n",
        "                           kernel_size=(3, 3),\n",
        "                           stride=stride,\n",
        "                           padding=padding,\n",
        "                           bias=False)]\n",
        "        if not last:\n",
        "            block += [nn.BatchNorm2d(depth_out),\n",
        "                      nn.LeakyReLU(0.2)]\n",
        "        \n",
        "        return block\n",
        "    \n",
        "    def _init_layers(self):\n",
        "        internal_layers = [*self._block(self.max_depth, self.max_depth),\n",
        "                           # Last layer different from the others : depth x 4 x 4 -> 1 x 1 x 1\n",
        "                           *self._block(self.max_depth, 1, True, 2, 0)]\n",
        "        \n",
        "        return nn.Sequential(*internal_layers)\n",
        "    \n",
        "    def _from_rgb(self, dim):\n",
        "        rgb_layer = self._block(self.ncc, dim)\n",
        "        \n",
        "        return nn.Sequential(*rgb_layer)\n",
        "    \n",
        "    def grow_network(self):\n",
        "        \"\"\"Add a new layer on the top of the descriminator.\"\"\"\n",
        "        last_resl = self.resl\n",
        "        self.resl = self.resl * 2\n",
        "        growing = f\"{self.resl}x{self.resl}->{last_resl}x{last_resl}\"\n",
        "        \n",
        "        print(f\"Growing network : {growing}, can take few seconds...\")\n",
        "        \n",
        "        self.layer_name = \"layer_\" + growing\n",
        "        \n",
        "        \n",
        "        # TODO: find a better way to handle the channels' dim\n",
        "        dim_in = self.dim\n",
        "        dim_out = self.dim * 2\n",
        "        \n",
        "        hist_from_rgb = get_named_module(self.model, \"rgb_layer\")\n",
        "        \n",
        "        # Add this layer to avoid a too brusk change when a new layer is added.\n",
        "        transition_from_rgb = nn.Sequential()\n",
        "        transition_from_rgb.add_module(\"downsample_from_rgb\",\n",
        "                                       nn.AvgPool2d(kernel_size=2))\n",
        "        transition_from_rgb.add_module(\"hist_from_rgb\", hist_from_rgb)\n",
        "        \n",
        "        # Add the new layer on the top of the descriminator\n",
        "        new_layer = nn.Sequential()\n",
        "        new_layer.add_module(\"new_from_rgb\", self._from_rgb(dim_in))\n",
        "        new_layer.add_module(\"new_layer\", nn.Sequential(*self._block(dim_in,\n",
        "                                                                  dim_out)))\n",
        "        \n",
        "        # Create the new model\n",
        "        new_model = nn.Sequential()\n",
        "        new_model.add_module(\"concatenate_block\",\n",
        "                             ConcatenateLayers(transition_from_rgb,\n",
        "                                               new_layer))\n",
        "        new_model.add_module(\"fadein\", FadeIn())\n",
        "        \n",
        "        for name, m in self.model.named_children():\n",
        "            if name != \"rgb_layer\":\n",
        "                new_model.add_module(name, m)\n",
        "                new_model[-1].load_state_dict(m.state_dict())\n",
        "                \n",
        "        self.model = new_model\n",
        "        self.dim //= 2\n",
        "        \n",
        "    def clean_network(self):\n",
        "        \"\"\"Once the new layer is completly fade in, remove the useless layers.\"\"\"\n",
        "        rgb_layer = get_named_module(self.model.concatenate_block.new_layer,\n",
        "                                    \"new_from_rgb\")\n",
        "        fadedIn_layer = get_named_module(self.model.concatenate_block.new_layer,\n",
        "                                        \"new_layer\")\n",
        "        \n",
        "        new_model = nn.Sequential()\n",
        "        new_model.add_module(\"rgb_layer\", rgb_layer)\n",
        "        new_model.add_module(self.layer_name, fadedIn_layer)\n",
        "        \n",
        "        for name, m in self.model.named_children():\n",
        "            if name not in [\"concatenate_block\", \"fadein\"]:\n",
        "                new_model.add_module(name, m)\n",
        "                new_model[-1].load_state_dict(m.state_dict())\n",
        "                \n",
        "        self.model = new_model\n",
        "    \n",
        "    def forward(self, input_):\n",
        "        output = self.model(input_)\n",
        "\n",
        "        return output.view(-1, 1).squeeze(1)\n",
        "    \n",
        "net_d = Discriminator(4, 1)\n",
        "# print(net_d)\n",
        "net_d.grow_network()\n",
        "print(net_d)\n",
        "net_d.clean_network()\n",
        "print(net_d)\n",
        "net_d.grow_network()\n",
        "print(net_d)\n",
        "net_d.clean_network()\n",
        "print(net_d)\n",
        "for img, _ in train_loader:\n",
        "    val = net_d(img)\n",
        "    \n",
        "    print(val.shape)\n",
        "    break"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Growing network : 16x16->8x8, can take few seconds...\n",
            "Discriminator(\n",
            "  (model): Sequential(\n",
            "    (concatenate_block): ConcatenateLayers(\n",
            "      (trans_layer): Sequential(\n",
            "        (downsample_from_rgb): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        (hist_from_rgb): Sequential(\n",
            "          (rgb_layer): Sequential(\n",
            "            (0): Conv2d(1, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): LeakyReLU(negative_slope=0.2)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (new_layer): Sequential(\n",
            "        (new_from_rgb): Sequential(\n",
            "          (0): Conv2d(1, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): LeakyReLU(negative_slope=0.2)\n",
            "        )\n",
            "        (new_layer): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): LeakyReLU(negative_slope=0.2)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (fadein): FadeIn()\n",
            "    (init_layers): Sequential(\n",
            "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "      (3): Conv2d(1024, 1, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Discriminator(\n",
            "  (model): Sequential(\n",
            "    (rgb_layer): Sequential(\n",
            "      (new_from_rgb): Sequential(\n",
            "        (0): Conv2d(1, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "    )\n",
            "    (layer_16x16->8x8): Sequential(\n",
            "      (new_layer): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "    )\n",
            "    (init_layers): Sequential(\n",
            "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "      (3): Conv2d(1024, 1, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Growing network : 32x32->16x16, can take few seconds...\n",
            "Discriminator(\n",
            "  (model): Sequential(\n",
            "    (concatenate_block): ConcatenateLayers(\n",
            "      (trans_layer): Sequential(\n",
            "        (downsample_from_rgb): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        (hist_from_rgb): Sequential(\n",
            "          (rgb_layer): Sequential(\n",
            "            (new_from_rgb): Sequential(\n",
            "              (0): Conv2d(1, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): LeakyReLU(negative_slope=0.2)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (new_layer): Sequential(\n",
            "        (new_from_rgb): Sequential(\n",
            "          (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): LeakyReLU(negative_slope=0.2)\n",
            "        )\n",
            "        (new_layer): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): LeakyReLU(negative_slope=0.2)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (fadein): FadeIn()\n",
            "    (layer_16x16->8x8): Sequential(\n",
            "      (new_layer): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "    )\n",
            "    (init_layers): Sequential(\n",
            "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "      (3): Conv2d(1024, 1, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Discriminator(\n",
            "  (model): Sequential(\n",
            "    (rgb_layer): Sequential(\n",
            "      (new_from_rgb): Sequential(\n",
            "        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "    )\n",
            "    (layer_32x32->16x16): Sequential(\n",
            "      (new_layer): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "    )\n",
            "    (layer_16x16->8x8): Sequential(\n",
            "      (new_layer): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "    )\n",
            "    (init_layers): Sequential(\n",
            "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "      (3): Conv2d(1024, 1, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mgKL4IGavjGO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iXDjs1IGvk37",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dimension of the latent space\n",
        "Z_dim = 100\n",
        "\n",
        "# Number of color channel in the final image\n",
        "ncc = 3\n",
        "\n",
        "# Number of internal node\n",
        "ngf, ndf = 64, 64\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KvAC2McyvtZy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}